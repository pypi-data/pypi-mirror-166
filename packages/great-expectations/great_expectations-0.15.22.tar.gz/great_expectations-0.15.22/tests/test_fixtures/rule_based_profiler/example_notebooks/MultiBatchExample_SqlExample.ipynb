{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0a5264-b003-4101-862f-45653f2aed1b",
   "metadata": {},
   "source": [
    "# How to write multi-batch `BatchRequest` - `Sql` Example\n",
    "* A `BatchRequest` facilitates the return of a `batch` of data from a configured `Datasource`. To find more about `Batches`, please refer to the [related documentation](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/how_to_get_a_batch_of_data_from_a_configured_datasource#1-construct-a-batchrequest). \n",
    "* A `BatchRequest` can return 0 or more Batches of data depending on the underlying data, and how it is configured. This guide will help you configure `BatchRequests` to return multiple batches, which can be used by\n",
    "   1. Self-Initializing Expectations to estimate parameters\n",
    "   2. DataAssistants to profile your data and create and Expectation suite with self-intialized parameters.\n",
    "   \n",
    "* Note : Multi-batch BatchRequests are not supported in `RuntimeDataConnector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54886b-4f88-46d9-9afe-dfd8bb061e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "from ruamel import yaml\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "import sqlite3\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa243d2-6905-403a-b47a-d89ba834b951",
   "metadata": {},
   "source": [
    "* Load `DataContext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1854b-2a75-422e-83bb-5509d868e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context: ge.DataContext = ge.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4462320-d76e-492c-96fb-f0ff8f788851",
   "metadata": {},
   "source": [
    "## Sql Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e04726",
   "metadata": {},
   "source": [
    "### Example Database\n",
    "\n",
    "Imagine we have a database of 1 table, with `yellow_tripdata_sample_2020`, corresponding to all 12 months' `taxi_trip` data for 2020.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29b60b-7e16-4978-acee-0dab368cde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to sqlite DB, and print the existing tables\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:@localhost/test_ci\"\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "engine = create_engine(CONNECTION_STRING)\n",
    "insp = inspect(engine)\n",
    "print(insp.get_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49515697-83a2-432d-8b74-33e2f01db72c",
   "metadata": {},
   "source": [
    "### `SimpleSqlDatasource` Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19a29c",
   "metadata": {},
   "source": [
    "In our example, we add a `SimpleSqlalchemyDatasource` named `taxi_multi_batch_sql_datasource` with 1 table.  The configuration for `yellow_tripdata_sample_2020` also contains 2 `partitioners` which correspond to names of `ConfiguredAssetSqlDataConnectors`. \n",
    "\n",
    "**Note**: This example only uses `tables`, but `introspection` could also be used. For more information, please refer to the document [How to configure a DataConnector for splitting and sampling tables in SQL](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/advanced/how_to_configure_a_dataconnector_for_splitting_and_sampling_tables_in_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635755a4-36b1-442f-968a-2fbdb9b146d8",
   "metadata": {},
   "source": [
    "The partitioner `whole_table` is built-in to GE, and takes the whole table and returns it as a single Batch. \n",
    "\n",
    "It gives the following output, which corresponds to our two tables: \n",
    "\n",
    "```bash \n",
    "Data Connectors:\n",
    "    whole_table : ConfiguredAssetSqlDataConnector\n",
    "    Available data_asset_names (1 of 1):\n",
    "        yellow_tripdata_sample_2020 (1 of 1): [{}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a8284",
   "metadata": {},
   "source": [
    "\n",
    "The partitioner `by_pickup_month` is configured by us, and uses a `splitter_method` to split the table values into multiple batches. The splitter we use is `split_on_year_and_month`, which creates Batches according to the `pickup_datetime` column which of type `timestamp` in the database schema. \n",
    "\n",
    "We also include  `whole_table` partitioner, which is built-in into the `SimpleSqlalchemyDatasource`.  With the `whole_table` partitioner, we are able to refer to the `yellow_tripdata_sample_2020` table as a data asset with a single batch. \n",
    "    \n",
    "Here is the output, which shows the data asset `yellow_tripdata_sample_2020` with 12 batches, each associated with a different `pickup_datetime`. These become our `batch_identifiers` that distinguish one `Batch` from another.\n",
    "\n",
    "```bash\n",
    "Data Connectors:\n",
    "\tby_pickup_month : ConfiguredAssetSqlDataConnector\n",
    "        Available data_asset_names (1 of 1):\n",
    "            yellow_tripdata_sample_2020 (3 of 12): [{'pickup_datetime': {'year': 2020, 'month': 1}}, {'pickup_datetime': {'year': 2020, 'month': 10}}, {'pickup_datetime': {'year': 2020, 'month': 11}}]\n",
    "            \n",
    "    whole_table : ConfiguredAssetSqlDataConnector\n",
    "        Available data_asset_names (1 of 1):\n",
    "            yellow_tripdata_sample_2020 (1 of 1): [{}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84150f65-bbd6-4b45-95ab-9590a29f116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource_config = {\n",
    "    \"name\": \"taxi_multi_batch_sql_datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"class_name\": \"SimpleSqlalchemyDatasource\",\n",
    "    \"connection_string\": CONNECTION_STRING,\n",
    "    \"tables\":{\n",
    "        \"yellow_tripdata_sample_2020\": {\n",
    "            \"partitioners\":{\n",
    "                \"whole_table\":{},\n",
    "                \"by_pickup_month\":{\n",
    "                    \"splitter_method\": \"split_on_year_and_month\",\n",
    "                    \"splitter_kwargs\": {\n",
    "                        \"column_name\": \"pickup_datetime\",\n",
    "                        }\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "\n",
    "    },\n",
    "}\n",
    "data_context.test_yaml_config(yaml.dump(datasource_config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636ffff-0ddc-48fd-a4cf-f8e139a5e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_datasource only if it doesn't already exist in our configuration\n",
    "try:\n",
    "    data_context.get_datasource(datasource_config[\"name\"])\n",
    "except ValueError:\n",
    "    data_context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438146be",
   "metadata": {},
   "source": [
    "## BatchRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117cdb0d",
   "metadata": {},
   "source": [
    "Depending on which `DataConnector` (ie. `Partitioner`) you send a `BatchRequest` to, you will retrieve a different number of `Batches`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc9c59",
   "metadata": {},
   "source": [
    "Single Batch returned by `whole_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"whole_table\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e74a05-3fd1-4e47-9105-b721dbcf3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f4fa5",
   "metadata": {},
   "source": [
    "Multi Batch returned by `by_pickup_month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32dbac9-af5d-4677-98f9-f098ef091b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"by_pickup_month\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a284bfd-00aa-4068-bc09-71c6dea627e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(batch_request=multi_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list # 12 batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790746ee",
   "metadata": {},
   "source": [
    "You can also get a single Batch from a multi-batch DataConnector by passing in `data_connector_query`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16612bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"by_pickup_month\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    "    data_connector_query={ \n",
    "        \"batch_filter_parameters\": {\"pickup_datetime\": {\"year\": 2020, \"month\": 1}}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request_from_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229815cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list[0].to_dict() # 'batch_identifiers': {'pickup_datetime': '2020-02'}},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907a6ef5",
   "metadata": {},
   "source": [
    "# Using auto-initializing `Expectations` to generate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe9c76",
   "metadata": {},
   "source": [
    "We will generate a `Validator` using our `multi_batch_batch_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(batch_request=multi_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eca55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_suite = data_context.create_expectation_suite(expectation_suite_name=\"example_sql_suite\", overwrite_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852deba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(batch_list=multi_batch_batch_list, expectation_suite=example_suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01a0e9",
   "metadata": {},
   "source": [
    "When you run methods on the validator, it will typically run on the most recent batch (index `-1`), even if the Validator has access to a longer Batch list. For example, notice that rows below are all associated with `pickup_datetime` being `9` (September, 2020). This is because the datetime values are stored lexicographically, meaning `1` and `11`, `12` values will appear **before** `2` and `3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7d827-ed51-4f83-ac41-33ae58416ef1",
   "metadata": {},
   "source": [
    "For simplicity, let's get a `validator` with the December `Batch`, which is in index `\"3\"` (after `1`, `10`, `11`). Notice that we are also casting the value as a `list` using the square brackets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b673bc-8583-4fc5-9aa0-db6ca62e240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(batch_list=[multi_batch_batch_list[3]], expectation_suite=example_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9cabd-b2bd-46de-9317-ba4e809342fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be66602",
   "metadata": {},
   "source": [
    "### Typical Workflow\n",
    "A `batch_list` becomes really useful when you are calculating parameters for auto-initializing Expectations, as they us a `RuleBasedProfiler` under-the-hood to calculate parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef9ad7",
   "metadata": {},
   "source": [
    "Here is an example running `expect_column_median_to_be_between()` by \"guessing\" at the `min_value` and `max_value`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.expect_column_median_to_be_between(column=\"trip_distance\", min_value=0, max_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d096f",
   "metadata": {},
   "source": [
    "The observed value for our `yellow_tripdata_sample_2020_01` table where `vendor_id` = `2`  is going to be `1.6`, which means the Expectation fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5016d8",
   "metadata": {},
   "source": [
    "Now we run the same expectation again, but this time with `auto=True`. This means the `median` values are going to calculated across the `batch_list` associated with the `Validator` (ie 3 Batches for `yellow_tripdata_sample_2020_01`), which gives the min value of `1.5` and the max value of `5.23`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd821c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.expect_column_median_to_be_between(column=\"trip_distance\", auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6c277",
   "metadata": {},
   "source": [
    "The `auto=True` will also automatically run the Expectation against the most recent Batch (which has an observed value of `1.61`) and the Expectation will pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8b938",
   "metadata": {},
   "source": [
    "You can now save the `ExpectationSuite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba880ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ec631",
   "metadata": {},
   "source": [
    "### Running the `ExpectationSuite` against single `Batch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477381f5",
   "metadata": {},
   "source": [
    "Now the ExpectationSuite can be used to validate single batches using a Checkpoint. In our example, let's validate a different table, `yellow_tripdata_sample_2020_02`, using the `ExpectationSuite` we built from `yellow_tripdata_sample_2020_01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747dea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_sql_datasource\",\n",
    "    data_connector_name=\"by_pickup_month\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    "    data_connector_query={ \n",
    "        \"batch_filter_parameters\": {\"pickup_datetime\": {\"year\": 2020, \"month\": 2}}\n",
    "    }\n",
    "\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_config = {\n",
    "    \"name\": \"my_checkpoint\",\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": single_batch_batch_request_from_multi,\n",
    "            \"expectation_suite_name\": \"example_sql_suite\",            \n",
    "        }\n",
    "    ],\n",
    "}\n",
    "data_context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_context.run_checkpoint(\n",
    "    checkpoint_name=\"my_checkpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6234082",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6914725d-85cc-4c9d-a93d-2d1c329eac74",
   "metadata": {},
   "source": [
    "# Loading Data into Postgresql Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a183e-f0df-40f4-b64f-439666e32ab4",
   "metadata": {},
   "source": [
    "* The following code can be used to build the postgres database used in this notebook. It is included (and commented out) for reference.\n",
    "* In order to load the data into a local `postgresql` database, please feel free to use the `docker-compose.yml` file available at `great_expectations/assets/docker/postgresql/`. \n",
    "\n",
    "### To spin up the `postgresql` database\n",
    "* Have [Docker Desktop](https://www.docker.com/products/docker-desktop/) running locally.\n",
    "* Navigate to `great_expectations/assets/docker/postgresql/`\n",
    "* Type `docker-compose up`\n",
    "* Then uncomment and run the following snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91c234-06a2-4e98-9d90-c999c2aad07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tests.test_utils import load_data_into_test_database\n",
    "# from typing import List\n",
    "# import sqlalchemy as sa\n",
    "# import pandas as pd\n",
    "# CONNECTION_STRING = \"postgresql+psycopg2://postgres:@localhost/test_ci\"\n",
    "\n",
    "# data_paths: List[str] = [\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-01.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-02.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-03.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-04.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-05.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-06.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-07.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-08.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-09.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-10.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-11.csv\",\n",
    "#      \"../../../test_sets/taxi_yellow_tripdata_samples/yellow_tripdata_sample_2020-12.csv\",\n",
    "# ]\n",
    "\n",
    "    \n",
    "# engine = sa.create_engine(CONNECTION_STRING)\n",
    "# connection = engine.connect()\n",
    "# table_name = \"yellow_tripdata_sample_2020\"\n",
    "# res = connection.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "# for data_path in data_paths:\n",
    "#     # This utility is not for general use. It is only to support testing.\n",
    "#     load_data_into_test_database(\n",
    "#         table_name=\"yellow_tripdata_sample_2020\",\n",
    "#         csv_path=data_path,\n",
    "#         connection_string=CONNECTION_STRING,\n",
    "#         load_full_dataset=True,\n",
    "#         drop_existing_table=False,\n",
    "#         convert_colnames_to_datetime=[\"pickup_datetime\", \"dropoff_datetime\"]\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d4cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
