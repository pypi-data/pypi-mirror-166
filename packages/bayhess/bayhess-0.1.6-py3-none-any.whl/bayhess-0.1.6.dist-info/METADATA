Metadata-Version: 2.1
Name: bayhess
Version: 0.1.6
Summary: Bayesian Hessian Approximation for Stochastic Optimization
Home-page: https://github.com/agcarlon/bayhess
Author: Andre Gustavo Carlon
Author-email: agcarlon@gmail.com
License: GPLv3
Project-URL: Documentation, https://bayhess.readthedocs.io/
Project-URL: Source, https://github.com/agcarlon/bayhess
Project-URL: Manuscript, https://arxiv.org/abs/2208.00441
Keywords: stochastic optimization,Bayesian inference
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Information Technology
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Education
Classifier: Topic :: Utilities
Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3 :: Only
Description-Content-Type: text/x-rst
License-File: LICENSE
Requires-Dist: numpy (>=1.19)
Requires-Dist: scipy (>=1.7.1)

Bayesian Hessian Approximation for Stochastic Optimization
----------------------------------------------------------

The BayHess package uses noisy curvature pairs (noisy gradient differences computed at different points) to compute Hessian approximations. These Hessian approximations can be used to accelerate the convergence in stochastic optimization in a quasi-Newton fashion. To find a Hessian approximation, a posterior distribution of the Hessian is built. The prior distribution is based on the Frobenius norm with determinant constraints to impose extreme eigenvalues constraints and the likelihood distribution is built from the secant equations given the observed curvature pairs. To find the maximizer of the log posterior, the BayHess package uses the Newton-CG method with a homotopy approach to deal with the logarithmic barrier determinant constraints.

For a detailed description of the method, convergence analysis and numerical results, check our `manuscript`_ named "Approximating Hessian matrices using Bayesian inference: a new approach for quasi-Newton methods in stochastic optimization". This package can be used with the `MICE`_ estimator.

A BayHess object is created by giving the dimensionality of the problem, and lower and upper bounds of the eigenvalues of the Hessian; i.e., strong convexity and smoothness parameters.

    bay = BayHess(n_dim=10, strong_conv=1e-3, smooth=1e4)

Curvature information is passed using the 'update_curv_pairs' method

    bay.update_curv_pairs(sk, yk)

Install BayHess fro PyPI as

    pip install bayhess

A repository with numerical examples can be found at

https://github.com/agcarlon/bayhess_numerics

The documentation of the BayHess package is available at

https://bayhess.readthedocs.io/




.. _manuscript: https://arxiv.org/abs/2208.00441
.. _MICE: https://pypi.org/project/mice/
