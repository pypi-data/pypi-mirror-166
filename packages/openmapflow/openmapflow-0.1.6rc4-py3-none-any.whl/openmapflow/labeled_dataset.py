from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional

import numpy as np
import pandas as pd

from openmapflow.config import PROJECT_ROOT
from openmapflow.config import DataPaths as dp
from openmapflow.constants import (
    CLASS_PROB,
    END,
    EO_DATA,
    EO_STATUS,
    EO_STATUS_DUPLICATE,
    EO_STATUS_EXPORT_FAILED,
    EO_STATUS_MISSING_VALUES,
    START,
    SUBSET,
)


def get_label_timesteps(labels: pd.DataFrame):
    if START not in labels.columns or END not in labels.columns:
        raise ValueError("Labels must have start and end columns")

    diff = pd.to_datetime(labels[END]) - pd.to_datetime(labels[START])
    return (diff / np.timedelta64(1, "M")).round().astype(int)


def _to_np(x: str) -> Optional[np.ndarray]:
    try:
        return np.array(eval(x))
    except TypeError:
        return None


def clean_df_condition(df: pd.DataFrame) -> pd.Series:
    return (
        (df[EO_STATUS] != EO_STATUS_MISSING_VALUES)
        & (df[EO_STATUS] != EO_STATUS_EXPORT_FAILED)
        & (df[EO_STATUS] != EO_STATUS_DUPLICATE)
        & (df[CLASS_PROB] != 0.5)
    )


def _label_eo_counts(df: pd.DataFrame) -> str:
    df = df[clean_df_condition(df)]
    label_counts = df[SUBSET].value_counts()
    eo_counts = df[df[EO_DATA].notnull()][SUBSET].value_counts()
    text = ""
    for subset in ["training", "validation", "testing"]:
        if subset not in label_counts:
            continue
        labels_in_subset = label_counts.get(subset, 0)
        features_in_subset = eo_counts.get(subset, 0)
        if labels_in_subset != features_in_subset:
            text += (
                f"\u2716 {subset}: {labels_in_subset} labels, "
                + f"but {features_in_subset} features\n"
            )
        else:
            positive_class_percentage = (
                df[df[SUBSET] == subset][CLASS_PROB] > 0.5
            ).sum() / labels_in_subset
            text += (
                f"\u2714 {subset} amount: {labels_in_subset}, "
                + f"positive class: {positive_class_percentage:.1%}\n"
            )
    return text


@dataclass
class LabeledDataset:
    """
    A labeled dataset represents a DataFrame where each row consists of:
    - A coordinate
    - A binary label for that coordinate (y)
    - The earth observation data for that coordinate (X)
    Together labels (y) and the associated earth observation data (X) can be used
    to train and evaluate a macine learning model a model.

    Args:
        dataset (str): The name of the dataset.
        country (str): The country of the dataset (can be 'global' for global datasets).
    """

    dataset: str = ""
    country: str = ""
    label_type: str = "binary"
    license: str = ""
    source: str = ""
    dataset_dir: Path = PROJECT_ROOT / dp.DATASETS

    def __post_init__(self):
        self.df_path = self.dataset_dir / (self.dataset + ".csv")

    def summary(self, df: pd.DataFrame) -> str:
        timesteps = get_label_timesteps(df).unique()
        eo_status_str = str(df[EO_STATUS].value_counts()).rsplit("\n", 1)[0]
        return (
            f"{self.dataset} (Timesteps: {','.join([str(int(t)) for t in timesteps])})\n"
            + "----------------------------------------------------------------------------\n"
            + eo_status_str
            + "\n"
            + _label_eo_counts(df)
            + "\n"
        )

    def load_df(
        self, skip_to_np: bool = False, check_eo_data: bool = True
    ) -> pd.DataFrame:
        """Load dataset (labels + earth observation data) as a DataFrame"""
        if not self.df_path.exists():
            print(self.create_dataset())
        df = pd.read_csv(self.df_path)
        df = df[clean_df_condition(df)].copy()
        if check_eo_data and df[EO_DATA].isnull().any():
            raise ValueError(
                f"{self.dataset} has missing earth observation data, "
                + "run openmapflow create-datasets"
            )
        if not skip_to_np:
            df[EO_DATA] = df[EO_DATA].apply(_to_np)
        return df

    def create_dataset(self):
        raise NotImplementedError


def create_datasets(datasets: List[LabeledDataset]):
    report = "DATASET REPORT (autogenerated, do not edit directly)"
    for d in datasets:
        summary = d.create_dataset()
        print(summary)
        report += "\n\n" + summary

    with (PROJECT_ROOT / dp.REPORT).open("w") as f:
        f.write(report)
