embed_dim: 10
mlp_layer: [256, 256, 256]
activation: 'relu'
num_layers: 6
dropout: 0.2
batch_norm: True