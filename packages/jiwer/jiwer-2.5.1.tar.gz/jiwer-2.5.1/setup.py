# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['jiwer']

package_data = \
{'': ['*']}

install_requires = \
['levenshtein==0.20.2']

setup_kwargs = {
    'name': 'jiwer',
    'version': '2.5.1',
    'description': 'Evaluate your speech-to-text system with similarity measures such as word error rate (WER)',
    'long_description': '# JiWER: Similarity measures for automatic speech recognition evaluation\n\nThis repository contains a simple python package to approximate the Word Error Rate (WER), Match Error Rate (MER), Word Information Lost (WIL) and Word Information Preserved (WIP) of a transcript.\nIt computes the minimum-edit distance between the ground-truth sentence and the hypothesis sentence of a speech-to-text API.\nThe minimum-edit distance is calculated using the Python C module [Levenshtein](https://github.com/maxbachmann/Levenshtein).\n\n_For a comparison between WER, MER and WIL, see: \\\nMorris, Andrew & Maier, Viktoria & Green, Phil. (2004). [From WER and RIL to MER and WIL: improved evaluation measures for connected speech recognition.](https://www.researchgate.net/publication/221478089_From_WER_and_RIL_to_MER_and_WIL_improved_evaluation_measures_for_connected_speech_recognition)_\n\n# Installation\n\nYou should be able to install this package using [poetry](https://python-poetry.org/docs/): \n\n```\n$ poetry add jiwer\n```\n\nOr, if you prefer old-fashioned pip and you\'re using Python >= `3.7`:\n\n```bash\n$ pip install jiwer\n```\n\n# Usage\n\nThe most simple use-case is computing the edit distance between two strings:\n\n```python\nfrom jiwer import wer\n\nground_truth = "hello world"\nhypothesis = "hello duck"\n\nerror = wer(ground_truth, hypothesis)\n```\n\nSimilarly, to get other measures:\n\n```python\nimport jiwer\n\nground_truth = "hello world"\nhypothesis = "hello duck"\n\nwer = jiwer.wer(ground_truth, hypothesis)\nmer = jiwer.mer(ground_truth, hypothesis)\nwil = jiwer.wil(ground_truth, hypothesis)\n\n# faster, because `compute_measures` only needs to perform the heavy lifting once:\nmeasures = jiwer.compute_measures(ground_truth, hypothesis)\nwer = measures[\'wer\']\nmer = measures[\'mer\']\nwil = measures[\'wil\']\n```\n\nYou can also compute the WER over multiple sentences:\n\n```python\nfrom jiwer import wer\n\nground_truth = ["hello world", "i like monthy python"]\nhypothesis = ["hello duck", "i like python"]\n\nerror = wer(ground_truth, hypothesis)\n```\n\nWe also provide the character error rate:\n\n```python\nfrom jiwer import cer\n\nground_truth = ["i can spell", "i hope"]\nhypothesis = ["i kan cpell", "i hop"]\n\nerror = cer(ground_truth, hypothesis)\n```\n\n# pre-processing\n\nIt might be necessary to apply some pre-processing steps on either the hypothesis or\nground truth text. This is possible with the transformation API:\n\n```python\nimport jiwer\n\nground_truth = "I like  python!"\nhypothesis = "i like Python?\\n"\n\ntransformation = jiwer.Compose([\n    jiwer.ToLowerCase(),\n    jiwer.RemoveWhiteSpace(replace_by_space=True),\n    jiwer.RemoveMultipleSpaces(),\n    jiwer.ReduceToListOfListOfWords(word_delimiter=" ")\n]) \n\njiwer.wer(\n    ground_truth, \n    hypothesis, \n    truth_transform=transformation, \n    hypothesis_transform=transformation\n)\n```\n\nBy default, the following transformation is applied to both the ground truth and the hypothesis.\nNote that is simply to get it into the right format to calculate the WER.\n\n```python\nimport jiwer \n\nwer_default = jiwer.Compose([\n    jiwer.RemoveMultipleSpaces(),\n    jiwer.Strip(),\n    jiwer.ReduceToListOfListOfWords(),\n])\n```\n\n### transforms\n\nWe provide some predefined transforms. See `jiwer.transformations`.\n\n#### Compose\n\n`jiwer.Compose(transformations: List[Transform])` can be used to combine multiple transformations. \n\nExample:\n```python\nimport jiwer \n\njiwer.Compose([\n    jiwer.RemoveMultipleSpaces(),\n    jiwer.ReduceToListOfListOfWords()\n])\n```\n\nNote that each transformation needs to end with `jiwer.ReduceToListOfListOfWords()`, as the library internally computes the word error rate\nbased on a double list of words.\n`\n\n#### ReduceToListOfListOfWords\n\n`jiwer.ReduceToListOfListOfWords(word_delimiter=" ")` can be used to transform one or more sentences into a list of lists of words. \nThe sentences can be given as a string (one sentence) or a list of strings (one or more sentences). This operation should be the final step\nof any transformation pipeline as the library internally computes the word error rate\nbased on a double list of words.\n\nExample:\n```python\nimport jiwer \n\nsentences = ["hi", "this is an example"]\n\nprint(jiwer.ReduceToListOfListOfWords()(sentences))\n# prints: [[\'hi\'], [\'this\', \'is\', \'an, \'example\']]\n```\n\n#### ReduceToSingleSentence\n\n`jiwer.ReduceToSingleSentence(word_delimiter=" ")` can be used to transform multiple sentences into a single sentence. \nThe sentences can be given as a string (one sentence) or a list of strings (one or more sentences). \nThis operation can be useful when the number of\nground truth sentences and hypothesis sentences differ, and you want to do a minimal\nalignment over these lists. Note that this creates an invariance: `wer([a, b], [a, b])` might not\nbe equal to `wer([b, a], [b, a])`. \n\nExample:\n```python\nimport jiwer \n\nsentences = ["hi", "this is an example"]\n\nprint(jiwer.ReduceToSingleSentence()(sentences))\n# prints: [\'hi this is an example\']\n```\n\n\n#### RemoveSpecificWords\n\n`jiwer.RemoveSpecificWords(words_to_remove: List[str])` can be used to filter out certain words.\nAs words are replaced with a ` ` character, make sure to that `jiwer.RemoveMultipleSpaces`, \n`jiwer.Strip()` and `jiwer.RemoveEmptyStrings` are present in the composition _after_  `jiwer.RemoveSpecificWords`.\n\nExample:\n```python\nimport jiwer \n\nsentences = ["yhe awesome", "the apple is not a pear", "yhe"]\n\nprint(jiwer.RemoveSpecificWords(["yhe", "the", "a"])(sentences))\n# prints: [\'  awesome\', \'  apple is not   pear\', \' \']\n# note the extra spaces\n```\n\n#### RemoveWhiteSpace\n\n`jiwer.RemoveWhiteSpace(replace_by_space=False)` can be used to filter out white space.\nThe whitespace characters are ` `, `\\t`, `\\n`, `\\r`, `\\x0b` and `\\x0c`.\nNote that by default space (` `) is also removed, which will make it impossible to split a sentence into a list of words by using `ReduceToListOfListOfWords` \nor `ReduceToSingleSentence`.\nThis can be prevented by replacing all whitespace with the space character. \nIf so, make sure that `jiwer.RemoveMultipleSpaces`, \n`jiwer.Strip()` and `jiwer.RemoveEmptyStrings` are present in the composition _after_  `jiwer.RemoveWhiteSpace`.\n\n\nExample:\n```python\nimport jiwer \n\nsentences = ["this is an example", "hello\\tworld\\n\\r"]\n\nprint(jiwer.RemoveWhiteSpace()(sentences))\n# prints: ["thisisanexample", "helloworld"]\n\nprint(jiwer.RemoveWhiteSpace(replace_by_space=True)(sentences))\n# prints: ["this is an example", "hello world  "]\n# note the trailing spaces\n```\n\n#### RemovePunctuation\n\n`jiwer.RemovePunctuation()` can be used to filter out punctuation. The punctuation characters are defined as\nall unicode characters whose catogary name starts with `P`. See https://www.unicode.org/reports/tr44/#General_Category_Values. \n\nExample:\n```python\nimport jiwer \n\nsentences = ["this is an example!", "hello. goodbye"]\n\nprint(jiwer.RemovePunctuation()(sentences))\n# prints: [\'this is an example\', "hello goodbye"]\n```\n\n#### RemoveMultipleSpaces\n\n`jiwer.RemoveMultipleSpaces()` can be used to filter out multiple spaces between words.\n\nExample:\n```python\nimport jiwer \n\nsentences = ["this is   an   example ", "  hello goodbye  ", "  "]\n\nprint(jiwer.RemoveMultipleSpaces()(sentences))\n# prints: [\'this is an example \', " hello goodbye ", " "]\n# note that there are still trailing spaces\n```\n\n#### Strip\n\n`jiwer.Strip()` can be used to remove all leading and trailing spaces.\n\nExample:\n```python\nimport jiwer \n\nsentences = [" this is an example ", "  hello goodbye  ", "  "]\n\nprint(jiwer.Strip()(sentences))\n# prints: [\'this is an example\', "hello goodbye", ""]\n# note that there is an empty string left behind which might need to be cleaned up\n```\n\n\n#### RemoveEmptyStrings\n\n`jiwer.RemoveEmptyStrings()` can be used to remove empty strings.\n\nExample:\n```python\nimport jiwer \n\nsentences = ["", "this is an example", " ",  "                "]\n\nprint(jiwer.RemoveEmptyStrings()(sentences))\n# prints: [\'this is an example\']\n```\n\n#### ExpandCommonEnglishContractions\n\n`jiwer.ExpandCommonEnglishContractions()` can be used to replace common contractions such as `let\'s` to `let us`.\n\nCurrently, this method will perform the following replacements. Note that `␣` is used to indicate a space (` `) to get\naround markdown rendering constrains.\n\n| Contraction   | transformed into |\n| ------------- |:----------------:|\n| `won\'t`       | `␣will not`      |\n| `can\'t`       | `␣can not`       |\n| `let\'s`       | `␣let us`        |\n| `n\'t`         | `␣not`           |\n| `\'re`         | `␣are`           |\n| `\'s`          | `␣is`            |\n| `\'d`          | `␣would`         |\n| `\'ll`         | `␣will`          |\n| `\'t`          | `␣not`           |\n| `\'ve`         | `␣have`          |\n| `\'m`          | `␣am`            |\n\nExample:\n```python\nimport jiwer \n\nsentences = ["she\'ll make sure you can\'t make it", "let\'s party!"]\n\nprint(jiwer.ExpandCommonEnglishContractions()(sentences))\n# prints: ["she will make sure you can not make it", "let us party!"]\n```\n\n#### SubstituteWords\n\n`jiwer.SubstituteWords(dictionary: Mapping[str, str])` can be used to replace a word into another word. Note that\nthe whole word is matched. If the word you\'re attempting to substitute is a substring of another word it will \nnot be affected. \nFor example, if you\'re substituting `foo` into `bar`, the word `foobar` will NOT be substituted into `barbar`.\n\nExample:\n```python\nimport jiwer \n\nsentences = ["you\'re pretty", "your book", "foobar"]\n\nprint(jiwer.SubstituteWords({"pretty": "awesome", "you": "i", "\'re": " am", \'foo\': \'bar\'})(sentences))\n\n# prints: ["i am awesome", "your book", "foobar"]\n```\n\n#### SubstituteRegexes\n\n`jiwer.SubstituteRegexes(dictionary: Mapping[str, str])` can be used to replace a substring matching a regex\n expression into another substring.\n\nExample:\n```python\nimport jiwer \n\nsentences = ["is the world doomed or loved?", "edibles are allegedly cultivated"]\n\n# note: the regex string "\\b(\\w+)ed\\b", matches every word ending in \'ed\', \n# and "\\1" stands for the first group (\'\\w+). It therefore removes \'ed\' in every match.\nprint(jiwer.SubstituteRegexes({r"doom": r"sacr", r"\\b(\\w+)ed\\b": r"\\1"})(sentences))\n\n# prints: ["is the world sacr or lov?", "edibles are allegedly cultivat"]\n```\n\n#### ToLowerCase\n\n`jiwer.ToLowerCase()` can be used to convert every character into lowercase.\n\nExample:\n```python\nimport jiwer \n\nsentences = ["You\'re PRETTY"]\n\nprint(jiwer.ToLowerCase()(sentences))\n\n# prints: ["you\'re pretty"]\n```\n\n#### ToUpperCase\n\n`jiwer.ToUpperCase()` can be used to replace every character into uppercase.\n\nExample:\n```python\nimport jiwer \n\nsentences = ["You\'re amazing"]\n\nprint(jiwer.ToUpperCase()(sentences))\n\n# prints: ["YOU\'RE AMAZING"]\n```\n\n#### RemoveKaldiNonWords\n\n`jiwer.RemoveKaldiNonWords()` can be used to remove any word between `[]` and `<>`. This can be useful when working\nwith hypotheses from the Kaldi project, which can output non-words such as `[laugh]` and `<unk>`.\n\nExample:\n```python\nimport jiwer \n\nsentences = ["you <unk> like [laugh]"]\n\nprint(jiwer.RemoveKaldiNonWords()(sentences))\n\n# prints: ["you  like "]\n# note the extra spaces\n```\n',
    'author': 'Nik Vaessen',
    'author_email': 'nikvaes@gmail.com',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://github.com/jitsi/jiwer',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.7,<4.0',
}


setup(**setup_kwargs)
